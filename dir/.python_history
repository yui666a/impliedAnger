python3
ls
!ls
from transformers import AutoTokenizer, RobertaModel
import torch
tokenizer = AutoTokenizer.from_pretrained("roberta-base")
model = RobertaModel.from_pretrained("roberta-base")
inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
outputs = model(**inputs)
last_hidden_states = outputs.last_hidden_state
from transformers import AutoTokenizer, RobertaForCausalLM, AutoConfig
import torch
tokenizer = AutoTokenizer.from_pretrained("roberta-base")
config = AutoConfig.from_pretrained("roberta-base")
config.is_decoder = True
model = RobertaForCausalLM.from_pretrained("roberta-base", config=config)
inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
outputs = model(**inputs)
prediction_logits = outputs.logits
import torch
print(torch.__version__)
print(torch.cuda.is_available())
print(torch.cuda.device_count())
print(torch.cuda)
import torch
torch.cuda.current_device()
print(torch.cuda.device_count())
print(torch.cuda.is_available())
# True
import torch
print(torch.cuda.device_count())
print(torch.cuda.is_available())
print(torch.__version__)
import torch
nums = torch.randn(2,2)
print(nums.cuda())
import torch
print(torch.__version__)
print(torch.cuda.is_available())
print(torch.cuda.device_count())
import torch
print(torch.__version__)
print(torch.cuda.is_available())
print(torch.cuda.device_count())
import inspect
import numpy
print(inspect.getfile(numpy))
import transformers
import sys
sys.path
sys.__path__
sys.path
import tokenizers
tokenizers.path
tokenizers.info()
import transformers
import keras
vocab = {"<s>": 0, "<pad>": 1, "</s>": 2, "reful": 3, "gent": 4}
vocab = {**vocab, **{"Ġafter": 5, "noon": 6, "Ġsun": 7}}
merges = ["Ġ a", "Ġ s", "r e", "f u", "g e", "n t"]
merges += ["e r", "n o", "o n", "i g", "h t"]
merges += ["Ġs u", "Ġa f", "ge nt", "no on", "re fu"]
merges += ["Ġsu n", "Ġaf t", "refu l", "Ġaft er"]
inputs = [" afternoon sun", "refulgent sun"]
tokenizer = keras_nlp.models.RobertaTokenizer(
    vocabulary=vocab,
    merges=merges,
)
import keras_nlp
vocab = {"<s>": 0, "<pad>": 1, "</s>": 2, "reful": 3, "gent": 4}
vocab = {**vocab, **{"Ġafter": 5, "noon": 6, "Ġsun": 7}}
merges = ["Ġ a", "Ġ s", "r e", "f u", "g e", "n t"]
merges += ["e r", "n o", "o n", "i g", "h t"]
merges += ["Ġs u", "Ġa f", "ge nt", "no on", "re fu"]
merges += ["Ġsu n", "Ġaf t", "refu l", "Ġaft er"]
inputs = [" afternoon sun", "refulgent sun"]
tokenizer = keras_nlp.models.RobertaTokenizer(
    vocabulary=vocab,
    merges=merges,
)
tokenizer(inputs)
