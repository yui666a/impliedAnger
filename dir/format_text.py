#!/usr/bin/env python
# coding: utf-8

import spacy

# import json
import pandas as pd
import emoji
import nagisa
import unicodedata
import re


BASE_PATH = "/home/nb-user/ksl_pub/suggestive_anger/data/fuman_survey"

# # install packages
get_ipython().system("pip install emoji nagisa")
get_ipython().system("pip install -U ginza ja-ginza ja_ginza")
get_ipython().system("python3 -m spacy download ja_core_news_sm")

# # Load Dataset


danwasMap = {
    "ä¸¦åˆ—": 0,
    "å¯¾æ¯”": 1,
    "è¦æœ›": 2,
    "æ¡ä»¶": 3,
    "åŸå› çµæœ": 4,
    "ä¾‹æç¤º": 5,
    "è©³ç´°åŒ–": 6,
    "ä¸»é¡Œé€£é–": 7,
    "ç„¦ç‚¹ä¸»é¡Œé€£é–": 8,
    "é †æ¥": 9,
    "é€†æ¥": 10,
    "çŸ­æ–‡": 11,
    "è³ªå•å¿œç­”": 12,
    "ç†ç”±": 13,
}
labelsMap = {0: "æ„Ÿæƒ…çš„æ”»æ’ƒ", 1: "æ„Ÿæƒ…çš„èª¬å¾—", 2: "ç†æ€§çš„èª¬å¾—", 3: "å«Œå‘³çš®è‚‰", 4: "é å›ã—", 5: "æ€’ã£ã¦ã„ãªã„"}

baseData = pd.read_json(BASE_PATH + "/json/human_data_ver5.json")
baseData = baseData.rename(columns={"fulltext": "text", "label": "labels"})
baseData["danwa_result"] = (
    baseData["danwa_result"].map(danwasMap).fillna(3).astype("int64")
)

kushiroData = pd.concat(
    [
        pd.read_csv(BASE_PATH + "/kosen_features.csv"),
        pd.read_csv(BASE_PATH + "/kosen_labels.csv"),
    ],
    axis=1,
)
kushiroData = kushiroData.rename(columns={"feature": "text", "label": "labels"})

baseData = pd.concat([baseData, kushiroData])
baseData = baseData.reset_index(drop=True)  # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®indexã‚’åˆ—ã¨ã—ã¦ä¿å­˜ã—ãªã„

print(baseData.labels.value_counts())
baseData


# # Load functions


def extract_emoji(words):
    """
    æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰çµµæ–‡å­—ğŸ˜‰ã‚’æŠ½å‡ºã™ã‚‹
    ï¼ˆé¡”æ–‡å­—ã¯æŠ½å‡ºã—ãªã„ï¼‰
    """
    words = str(words)
    return [w for w in words if emoji.is_emoji(str(w))]


# In[9]:

KAOMOJI_LEN = 5


def extract_kaomoji(text):
    """ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æŠ½å‡ºã—ãŸé¡”æ–‡å­—ãƒªã‚¹ãƒˆã‚’è¿”å´ã™ã‚‹ã€‚
    â†’ ï¼¼(^o^)ï¼, m(_ _)m ãªã©ã® æ‰‹ã‚’å«ã‚€é¡”æ–‡å­—ãŒã‚ã‚Œã°ã€ãã‚Œã‚‚æŠ½å‡ºã™ã‚‹
    """
    results = nagisa.extract(text, extract_postags=["è£œåŠ©è¨˜å·"])
    words = results.words
    kaomoji_words = []
    kaomoji_idx = [i for i, w in enumerate(words) if len(w) >= KAOMOJI_LEN]
    kaomoji_hands = ["ãƒ", "ãƒ½", "âˆ‘", "m", "O", "o", "â”", "/", "\\", "â”Œ"]
    # é¡”æ–‡å­—ã¨æ‰‹ã‚’æ¤œç´¢
    for i in kaomoji_idx:
        kaomoji = words[i]  # é¡”æ–‡å­—åˆ—
        try:
            # é¡”æ–‡å­—ã®å·¦æ‰‹
            if words[i - 1] in kaomoji_hands and 0 < i:
                kaomoji = words[i - 1] + kaomoji
            # é¡”æ–‡å­—ã®å³æ‰‹
            if words[i + 1] in kaomoji_hands:
                kaomoji = kaomoji + words[i + 1]
        except IndexError:
            pass
        finally:
            kaomoji_words.append(kaomoji)
    return kaomoji_words


# In[10]:


# nlp = spacy.load("ja_ginza")
nlp = spacy.load("ja_core_news_sm")


def separate_sentence(feature):
    doc = nlp(feature)
    return [str(sent) for sent in doc.sents]


def delete(text, target_list):
    for target in target_list:
        text = text.replace(target, "")
    return text


# In[11]:


def replace_emoji(sentence):
    return (
        sentence.replace("â—", "!")
        .replace("â“", "?")
        .replace("â€¼ï¸", "!!")
        .replace("â‰ï¸", "!?")
    )
    # return sentence.replace('â—', 'ï¼').replace('â“', 'ï¼Ÿ').replace('â€¼ï¸', 'ï¼ï¼').replace('â‰ï¸', 'ï¼ï¼Ÿ')


def delete_emoji(sentence):
    emoji_list = extract_emoji(sentence)
    if len(emoji_list) == 0:
        return sentence

    for e in emoji_list:
        sentence = sentence.replace(e, "")
    return sentence


def delete_kaomoji(sentence):
    sentence = sentence.replace("ã€€", "").replace(" ", "")

    if "(^^;;" in sentence:
        sentence = sentence.replace("(^^;;", "")

    if "ÌĞ´`;" in sentence:
        sentence = sentence.replace("ÌĞ´`;", "")

    kaomoji_list = extract_kaomoji(sentence)
    if len(kaomoji_list) == 0:
        return sentence

    for kaomoji in kaomoji_list:
        """unicode_sentence = unicodedata.normalize('NFKC', sentence)
        print(kaomoji)
        print(unicode_sentence)
        print(kaomoji in unicode_sentence)"""
        sentence = sentence.replace(kaomoji, "")
    return sentence


tilde_pattern = "[\u007E\u02DC\u0303\u1FC0\u2053\u223C\u223F\u3030\uFF5E]"
comma_pattern = r"[ï½¤ã€]{2,}"
full_stop_pattern = r"[ï½¡ã€‚]{2,}"
unnecessary_full_stop_pattern = r"([!?]+)[ï½¡ã€‚]+"
number_pattern = r"[0-9]+"
compiled_tilde = re.compile(tilde_pattern)
compiled_comma = re.compile(comma_pattern)
compiled_full_stop = re.compile(full_stop_pattern)
compiled_unnecessary = re.compile(unnecessary_full_stop_pattern)
compiled_number = re.compile(number_pattern)


def delete_slash(feature):
    return feature.replace("/", "")


def fix_tilde(feature):
    return compiled_tilde.sub("ã€œ", feature)


def fix_multiple_punctuation(feature):
    return compiled_comma.sub(
        "ã€", compiled_full_stop.sub("ã€‚", compiled_unnecessary.sub(r"\1", feature))
    )


def delete_irregular_str(feature):
    return feature.replace("\uFE0E", "").replace("\uFE0F", "")


def replace_number_to_zero(feature):
    match_list = compiled_number.findall(feature)
    for match_str in match_list:
        feature = feature.replace(match_str, "0")
    return feature


# æ–‡ã”ã¨ã«åˆ†ã‘ãŸã‚ã¨ã®å‡¦ç†
def fix_bracket(sentences, left_bracket, right_bracket):
    count_left_bracket = sum([s.count(left_bracket) for s in sentences])
    count_right_bracket = sum([s.count(right_bracket) for s in sentences])

    if count_left_bracket == 0 and count_left_bracket == count_right_bracket:
        return sentences

    # print(f'count_left_bracket : {count_left_bracket}')
    sentence_length = len(sentences)
    new_sentences = []
    should_skip = False

    for i in range(sentence_length):
        if should_skip:
            should_skip = False
            continue

        if sentences[i].count(left_bracket) == sentences[i].count(right_bracket):
            new_sentences.append(sentences[i])
            continue

        right_bracket_position = i + 1

        if i != sentence_length - 1 and sentences[right_bracket_position].count(
            left_bracket
        ) != sentences[right_bracket_position].count(right_bracket):
            new_sentences.append(sentences[i] + sentences[right_bracket_position])
            should_skip = True

    return new_sentences


symbol_pattern = r"^[.!?]+"
leader_pattern = r"[.ãƒ»]{2,}"
end_of_sentence_pattern = r"[ã€‚!?]$"
compiled_symbol = re.compile(symbol_pattern)
compiled_leader = re.compile(leader_pattern)
compiled_eos = re.compile(end_of_sentence_pattern)


def join_symbol_only_sentence(sentences):
    sentence_length = len(sentences)
    new_sentences = []
    is_matched = False

    for i in range(sentence_length):
        if is_matched:
            is_matched = False
            continue

        if compiled_symbol.match(sentences[i]) is None or i == 0:
            new_sentences.append(sentences[i])
            continue

        new_sentences[-1] += sentences[i]
        should_skip = True

    return new_sentences


def restore_leader(sentences):
    return [
        compiled_leader.sub("â€¦", sentence)
        if compiled_leader.search(sentence)
        else sentence
        for sentence in sentences
    ]


def delete_sentence_only_symbols(sentences):
    return [s for s in sentences if s != "ã€"]


def join_sentence_if_start_left_paren(sentences):
    new_sentence = []
    for i, sentence in enumerate(sentences):
        if i == 0:
            new_sentence.append(sentence)
            continue

        if sentence[0] == "(":
            new_sentence[-1] += sentence
        else:
            new_sentence.append(sentence)

    return new_sentence


def fix_end_of_sentence(sentences):
    return [
        sentence if compiled_eos.search(sentence) else sentence + "ã€‚"
        for sentence in sentences
    ]


def make_sentences_from_feature(feature):
    sentences = separate_sentence(
        replace_number_to_zero(
            delete_irregular_str(
                fix_multiple_punctuation(
                    fix_tilde(
                        delete_slash(
                            delete_emoji(delete_kaomoji(replace_emoji(feature)))
                        )
                    )
                )
            )
        )
    )
    return fix_end_of_sentence(
        join_sentence_if_start_left_paren(
            delete_sentence_only_symbols(
                restore_leader(
                    join_symbol_only_sentence(
                        fix_bracket(
                            fix_bracket(fix_bracket(sentences, "ã€Œ", "ã€"), "ã€", "ã€"),
                            "(",
                            ")",
                        )
                    )
                )
            )
        )
    )


# In[13]:


features = []

for i, data in enumerate(baseData.values):
    feature = data[0]
    feature = unicodedata.normalize("NFKC", feature)  # NFKCæ­£è¦åŒ–
    # emoji_list = extract_emoji(feature)
    result = make_sentences_from_feature(feature)
    line_length = len(result)
    sentence = " ".join(result)
    features.append([i, line_length, sentence])  # [index, æ–‡ç« æ•°, æœ¬æ–‡]
    # for sentence_i, sentence in enumerate(result):
    #     # index, ä½•æ–‡ç« ç›®ã‹, æ–‡ç« æ•°, æœ¬æ–‡
    #     features.append([i, sentence_i, len_result, sentence])
