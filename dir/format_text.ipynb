{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b42fad-1751-4914-befa-acaa667a1d21",
   "metadata": {
    "tags": []
   },
   "source": [
    "# install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a58225-60a8-4500-ad8a-84f203ba6bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in ./.local/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: nagisa in ./.local/lib/python3.10/site-packages (0.2.8)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from nagisa) (1.16.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from nagisa) (1.23.5)\n",
      "Requirement already satisfied: DyNet38 in ./.local/lib/python3.10/site-packages (from nagisa) (2.1)\n",
      "Requirement already satisfied: cython in ./.local/lib/python3.10/site-packages (from DyNet38->nagisa) (0.29.34)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ginza in ./.local/lib/python3.10/site-packages (5.1.2)\n",
      "Requirement already satisfied: ja-ginza in ./.local/lib/python3.10/site-packages (5.1.2)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.2.0 in ./.local/lib/python3.10/site-packages (from ginza) (3.4.4)\n",
      "Requirement already satisfied: plac>=1.3.3 in ./.local/lib/python3.10/site-packages (from ginza) (1.3.5)\n",
      "Requirement already satisfied: SudachiPy<0.7.0,>=0.6.2 in ./.local/lib/python3.10/site-packages (from ginza) (0.6.7)\n",
      "Requirement already satisfied: SudachiDict-core>=20210802 in ./.local/lib/python3.10/site-packages (from ginza) (20230110)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (2.4.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (1.10.5)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.5.0,>=3.2.0->ginza) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.2.0->ginza) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.2.0->ginza) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.2.0->ginza) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.2.0->ginza) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.2.0->ginza) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.2.0->ginza) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.2.0->ginza) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.2.0->ginza) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.local/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.2.0->ginza) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.2.0->ginza) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "/home/nb-user/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-05-19 15:07:22.441646: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-19 15:07:25.813196: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\n",
      "\u001b[38;5;1m✘ No compatible package found for 'ja_ginza' (spaCy v3.4.4)\u001b[0m\n",
      "\n",
      "/home/nb-user/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-05-19 15:07:32.614988: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-19 15:07:35.037725: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ja-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ja_core_news_sm-3.4.0/ja_core_news_sm-3.4.0-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in ./.local/lib/python3.10/site-packages (from ja-core-news-sm==3.4.0) (3.4.4)\n",
      "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in ./.local/lib/python3.10/site-packages (from ja-core-news-sm==3.4.0) (0.6.7)\n",
      "Requirement already satisfied: sudachidict-core>=20211220 in ./.local/lib/python3.10/site-packages (from ja-core-news-sm==3.4.0) (20230110)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (1.10.5)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.local/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.local/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->ja-core-news-sm==3.4.0) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ja_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji nagisa \n",
    "!pip install -U ginza ja-ginza ja_ginza\n",
    "!python3 -m spacy download ja_ginza\n",
    "!python3 -m spacy download ja_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a24944-e6b3-4e84-852c-0bf0a7476ff8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f222d48-3abd-4338-9f81-14ce6a220a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "2    1076\n",
      "1     758\n",
      "0     282\n",
      "4     233\n",
      "5     227\n",
      "3     224\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>danwa_result</th>\n",
       "      <th>result_form</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>最近の内容は、のび太が、他力本願ですぐ調子にのり、エゴが強すぎると感じている。子供に見せたく...</td>\n",
       "      <td>[最近の内容は、のび太が、他力本願ですぐ調子にのり、エゴが強すぎると感じている, 子供に見せ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'3': '1.0', '0': '1.0', '1': '7.0', '2': '4.0'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ヤクルトの舌や喉に何か残る感じの、あれは何でしょう?すごくいやだ。</td>\n",
       "      <td>[ヤクルトの舌や喉に何か残る感じの、あれは何でしょう?すごくいやだ]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>{'0': '7.0', '1': '2.0', '3': '2.0', '2': '1.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>めばちこ痛い。治ってもまたできる...</td>\n",
       "      <td>[めばちこ痛い, 治ってもまたできる...]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'0': '1.0', '5': '12.0'}</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>タケダは、からだ浸透補水液は病院の消毒液を連想させる味がします。体に良くても飲み物としてなじ...</td>\n",
       "      <td>[タケダは、からだ浸透補水液は病院の消毒液を連想させる味がします, 体に良くても飲み物として...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'2': '1.0', '1': '3.0', '4': '1.0', '3': '8.0'}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>チョコリングの個性が弱くて商品として地味で美味しくない。</td>\n",
       "      <td>[チョコリングの個性が弱くて商品として地味で美味しくない]</td>\n",
       "      <td>9.0</td>\n",
       "      <td>{'0': '1.0', '2': '8.0', '5': '1.0', '1': '3.0'}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>マクドナルドなのにポケモンgoのストップが効かない。ストップはマックドナルドの表示になってる...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>早くポケモンを追加して欲しい。そろそろ飽きてきます</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>ゲームセンターCXを深夜枠でもいいから地上波でしてもらいたい。</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>ヤフーニュースのコメントが酷いの多くて不満。誹謗中傷とかは削除するようにしてほしいわ。</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>夜のコース料理が8000円からと高いのでもう少しリーズナブルにしてほしい</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   \n",
       "0     最近の内容は、のび太が、他力本願ですぐ調子にのり、エゴが強すぎると感じている。子供に見せたく...  \\\n",
       "1                     ヤクルトの舌や喉に何か残る感じの、あれは何でしょう?すごくいやだ。   \n",
       "2                                   めばちこ痛い。治ってもまたできる...   \n",
       "3     タケダは、からだ浸透補水液は病院の消毒液を連想させる味がします。体に良くても飲み物としてなじ...   \n",
       "4                          チョコリングの個性が弱くて商品として地味で美味しくない。   \n",
       "...                                                 ...   \n",
       "2795  マクドナルドなのにポケモンgoのストップが効かない。ストップはマックドナルドの表示になってる...   \n",
       "2796                          早くポケモンを追加して欲しい。そろそろ飽きてきます   \n",
       "2797                    ゲームセンターCXを深夜枠でもいいから地上波でしてもらいたい。   \n",
       "2798        ヤフーニュースのコメントが酷いの多くて不満。誹謗中傷とかは削除するようにしてほしいわ。   \n",
       "2799               夜のコース料理が8000円からと高いのでもう少しリーズナブルにしてほしい   \n",
       "\n",
       "                                              sentences  danwa_result   \n",
       "0     [最近の内容は、のび太が、他力本願ですぐ調子にのり、エゴが強すぎると感じている, 子供に見せ...           4.0  \\\n",
       "1                    [ヤクルトの舌や喉に何か残る感じの、あれは何でしょう?すごくいやだ]           6.0   \n",
       "2                                [めばちこ痛い, 治ってもまたできる...]           0.0   \n",
       "3     [タケダは、からだ浸透補水液は病院の消毒液を連想させる味がします, 体に良くても飲み物として...           5.0   \n",
       "4                         [チョコリングの個性が弱くて商品として地味で美味しくない]           9.0   \n",
       "...                                                 ...           ...   \n",
       "2795                                                NaN           NaN   \n",
       "2796                                                NaN           NaN   \n",
       "2797                                                NaN           NaN   \n",
       "2798                                                NaN           NaN   \n",
       "2799                                                NaN           NaN   \n",
       "\n",
       "                                            result_form  labels  \n",
       "0      {'3': '1.0', '0': '1.0', '1': '7.0', '2': '4.0'}       1  \n",
       "1     {'0': '7.0', '1': '2.0', '3': '2.0', '2': '1.0...       0  \n",
       "2                             {'0': '1.0', '5': '12.0'}       5  \n",
       "3      {'2': '1.0', '1': '3.0', '4': '1.0', '3': '8.0'}       3  \n",
       "4      {'0': '1.0', '2': '8.0', '5': '1.0', '1': '3.0'}       2  \n",
       "...                                                 ...     ...  \n",
       "2795                                                NaN       2  \n",
       "2796                                                NaN       2  \n",
       "2797                                                NaN       2  \n",
       "2798                                                NaN       1  \n",
       "2799                                                NaN       2  \n",
       "\n",
       "[2800 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "danwasMap = {'並列':0, '対比':1, '要望':2, '条件':3, '原因結果':4, '例提示':5, '詳細化':6, '主題連鎖':7, '焦点主題連鎖':8,'順接':9, '逆接':10, '短文':11, '質問応答':12, '理由':13}\n",
    "labelsMap = {0: \"感情的攻撃\", 1: \"感情的説得\", 2: \"理性的説得\", 3: \"嫌味皮肉\", 4: \"遠回し\", 5: \"怒っていない\"}\n",
    "\n",
    "baseData = pd.read_json(\"/home/nb-user/ksl_pub/suggestive_anger/data/fuman_survey/json/human_data_ver5.json\")\n",
    "baseData = baseData.rename(columns={'fulltext': 'text', \"label\": \"labels\"})\n",
    "baseData['danwa_result'] = baseData['danwa_result'].map(danwasMap).fillna(3).astype('int64')\n",
    "# baseData = baseData[[\"text\", \"labels\"]]\n",
    "# baseData.to_csv(\"/content/drive/MyDrive/LAB/研究/human_data_ver5.csv\")\n",
    "\n",
    "kushiroFeature = pd.read_csv(\"/home/nb-user/ksl_pub/suggestive_anger/data/fuman_survey/kosen_features.csv\")\n",
    "kushiroLabel = pd.read_csv(\"/home/nb-user/ksl_pub/suggestive_anger/data/fuman_survey/kosen_labels.csv\")\n",
    "kushiroData = pd.concat([kushiroFeature, kushiroLabel], axis=1)\n",
    "kushiroData = kushiroData.rename(columns={'feature': 'text', \"label\": \"labels\"})\n",
    "\n",
    "baseData = pd.concat([baseData, kushiroData])\n",
    "baseData = baseData.reset_index(\n",
    "    drop=True # オリジナルのindexを列として保存しない\n",
    ")\n",
    "\n",
    "print(baseData.labels.value_counts())\n",
    "baseData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab49f7f-6f5b-4944-aa3c-eec0bfae5f79",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf12cd9-769d-4a74-9199-64ed4d3113ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[dynet] random seed: 1234\n",
      "[dynet] allocating memory: 32MB\n",
      "[dynet] memory allocation done.\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import nagisa\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_emoji(words):\n",
    "    \"\"\"\n",
    "    日本語のテキストから絵文字😉を抽出する  \n",
    "    （顔文字は抽出しない）\n",
    "    \"\"\"\n",
    "    words = str(words)\n",
    "    return [w for w in words if emoji.is_emoji(str(w))]\n",
    "    # return [w for w in words if w in emoji.UNICODE_EMOJI_ENGLISH]\n",
    "\n",
    "\n",
    "# text = \"今日は渋谷スクランブルスクエアに行ってきた＼(^o^)／ 夜景🏙サイコー❗️ https://hogehogehogehoge.jpg\"\n",
    "# text = unicodedata.normalize('NFKC', text) # NFKC正規化\n",
    "# print(text)\n",
    "# print(extract_emoji(text))\n",
    "# # => ['🏙', '❗']\n",
    "\n",
    "# text = \"日本語のテキストから絵文字😉を抽出するよ❗\"\n",
    "# text = unicodedata.normalize('NFKC', text) # NFKC正規化\n",
    "# print(text)\n",
    "# print(extract_emoji(text))\n",
    "# # => ['😉', '❗']\n",
    "\n",
    "\n",
    "# for i, data in enumerate(baseData.values):\n",
    "#     feature = data[0]\n",
    "#     if i < 10:\n",
    "#         print(f'i : {i}\\tfeature : {feature}')\n",
    "#     if '(*́ー`*)' in feature:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e95ee0b8-caa6-4541-b75c-01f3ede9b58a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "KAOMOJI_LEN = 5\n",
    "\n",
    "def extract_kaomoji(text):\n",
    "    \"\"\" 与えられたテキストから抽出した顔文字リストを返却する。\n",
    "        → ＼(^o^)／, m(_ _)m などの 手を含む顔文字があれば、それも抽出する\n",
    "    \"\"\"\n",
    "    results = nagisa.extract(text, extract_postags=['補助記号'])\n",
    "    words = results.words\n",
    "    kaomoji_words = []\n",
    "    kaomoji_idx = [i for i, w in enumerate(words) if len(w) >= KAOMOJI_LEN]\n",
    "    kaomoji_hands = ['ノ', 'ヽ', '∑', 'm', 'O', 'o', '┐', '/', '\\\\', '┌'] \n",
    "    # 顔文字と手を検索\n",
    "    for i in kaomoji_idx:\n",
    "        kaomoji = words[i] # 顔文字列\n",
    "        try:\n",
    "            # 顔文字の左手\n",
    "            if words[i-1] in kaomoji_hands and 0 < i:\n",
    "                kaomoji = words[i-1] + kaomoji\n",
    "            # 顔文字の右手\n",
    "            if words[i+1] in kaomoji_hands:\n",
    "                kaomoji = kaomoji + words[i+1]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        finally:\n",
    "            kaomoji_words.append(kaomoji)\n",
    "    return kaomoji_words\n",
    "\n",
    "\n",
    "# for index, row in baseData.iterrows():\n",
    "#   text = unicodedata.normalize('NFKC', row[\"text\"]) # NFKC正規化\n",
    "#   emoji = extract_kaomoji(text)\n",
    "#   if emoji: \n",
    "#     print(index, emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74516c4a-abdb-4bf7-9716-70d236dae814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# nlp = spacy.load(\"ja_ginza\")\n",
    "nlp = spacy.load(\"ja_core_news_sm\")\n",
    "\n",
    "def separate_sentence(feature):\n",
    "    doc = nlp(feature)\n",
    "    return [str(sent) for sent in doc.sents]\n",
    "\n",
    "\n",
    "def delete(text, target_list):\n",
    "    for target in target_list:\n",
    "        text = text.replace(target, '')\n",
    "    return text\n",
    "\n",
    "\n",
    "# for index, row in baseData.iterrows():\n",
    "#   text = unicodedata.normalize('NFKC', row[\"text\"].replace(' ', ''))\n",
    "#   target_list = extract_kaomoji(text)\n",
    "#   cleaned_text = delete(text, target_list)\n",
    "#   if target_list:\n",
    "#     [print(target_list)]\n",
    "#     print(row[\"text\"].replace(' ', ''))\n",
    "#     print(separate_sentence(cleaned_text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eb90f2b-1cbf-4dea-af89-cf856b27f741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_emoji(sentence):\n",
    "    return sentence.replace('❗', '!').replace('❓', '?').replace('‼️', '!!').replace('⁉️', '!?')\n",
    "    # return sentence.replace('❗', '！').replace('❓', '？').replace('‼️', '！！').replace('⁉️', '！？')\n",
    "\n",
    "\n",
    "def delete_emoji(sentence):\n",
    "    emoji_list = extract_emoji(sentence)\n",
    "    if len(emoji_list) == 0:\n",
    "        return sentence\n",
    "    \n",
    "    for e in emoji_list:\n",
    "        sentence = sentence.replace(e, '')\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def delete_kaomoji(sentence):\n",
    "    sentence = sentence.replace('　', '').replace(' ', '')\n",
    "    \n",
    "    if '(^^;;' in sentence:\n",
    "        sentence = sentence.replace('(^^;;', '')\n",
    "    \n",
    "    if '́д`;' in sentence:\n",
    "        sentence = sentence.replace('́д`;', '')\n",
    "    \n",
    "    kaomoji_list = extract_kaomoji(sentence)\n",
    "    if len(kaomoji_list) == 0:\n",
    "        return sentence\n",
    "    \n",
    "    for kaomoji in kaomoji_list:\n",
    "        \"\"\"unicode_sentence = unicodedata.normalize('NFKC', sentence)\n",
    "        print(kaomoji)\n",
    "        print(unicode_sentence)\n",
    "        print(kaomoji in unicode_sentence)\"\"\"\n",
    "        sentence = sentence.replace(kaomoji, '')\n",
    "    return sentence\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ec1a97-5aae-432e-8702-812ce4786fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def check(position, sentences):\n",
    "#     for i, sentence in enumerate(sentences):\n",
    "#         # print(sentence)\n",
    "#         if sentence[0] == '(':\n",
    "#             print(sentence)\n",
    "#             print('')\n",
    "#             print(sentences)\n",
    "#             print('')\n",
    "#     return\n",
    "\n",
    "import re\n",
    "# pattern = '^[.,!?/、。・？！]+$'\n",
    "# repatter = re.compile(pattern)\n",
    "# def fix_symbol(sentences):\n",
    "#     return [s for s in sentences if repatter.match(s) is None]\n",
    "\n",
    "tilde_pattern = '[\\u007E\\u02DC\\u0303\\u1FC0\\u2053\\u223C\\u223F\\u3030\\uFF5E]'\n",
    "comma_pattern = r'[､、]{2,}'\n",
    "full_stop_pattern = r'[｡。]{2,}'\n",
    "unnecessary_full_stop_pattern = r'([!?]+)[｡。]+'\n",
    "number_pattern = r'[0-9]+'\n",
    "compiled_tilde = re.compile(tilde_pattern)\n",
    "compiled_comma = re.compile(comma_pattern)\n",
    "compiled_full_stop = re.compile(full_stop_pattern)\n",
    "compiled_unnecessary = re.compile(unnecessary_full_stop_pattern)\n",
    "compiled_number = re.compile(number_pattern)\n",
    "\n",
    "\n",
    "def delete_slash(feature):\n",
    "    return feature.replace('/', '')\n",
    "\n",
    "\n",
    "def fix_tilde(feature):\n",
    "    return compiled_tilde.sub('〜', feature)\n",
    "\n",
    "\n",
    "def fix_multiple_punctuation(feature):\n",
    "    return compiled_comma.sub(\n",
    "        '、', compiled_full_stop.sub(\n",
    "            '。', compiled_unnecessary.sub(r'\\1', feature)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def delete_irregular_str(feature):\n",
    "    return feature.replace('\\uFE0E', '').replace('\\uFE0F', '')\n",
    "\n",
    "\n",
    "def replace_number_to_zero(feature):\n",
    "    match_list = compiled_number.findall(feature)\n",
    "    for match_str in match_list:\n",
    "        feature = feature.replace(match_str, '0')\n",
    "    return feature\n",
    "\n",
    "\n",
    "# 文ごとに分けたあとの処理\n",
    "def fix_bracket(sentences, left_bracket, right_bracket):\n",
    "    count_left_bracket  = sum([s.count(left_bracket) for s in sentences])\n",
    "    count_right_bracket = sum([s.count(right_bracket) for s in sentences])\n",
    "    \n",
    "    if (count_left_bracket == 0\n",
    "        and count_left_bracket == count_right_bracket):\n",
    "        return sentences\n",
    "    \n",
    "    # print(f'count_left_bracket : {count_left_bracket}')\n",
    "    sentence_length = len(sentences)\n",
    "    new_sentences = []\n",
    "    should_skip = False\n",
    "    \n",
    "    for i in range(sentence_length):\n",
    "        if should_skip:\n",
    "            should_skip = False\n",
    "            continue\n",
    "        \n",
    "        if sentences[i].count(left_bracket) == sentences[i].count(right_bracket):\n",
    "            new_sentences.append(sentences[i])\n",
    "            continue\n",
    "        \n",
    "        right_bracket_position = i + 1\n",
    "        \n",
    "        if (i != sentence_length - 1\n",
    "            and sentences[right_bracket_position].count(left_bracket)\n",
    "            != sentences[right_bracket_position].count(right_bracket)):\n",
    "            new_sentences.append(sentences[i] + sentences[right_bracket_position])\n",
    "            should_skip = True\n",
    "    \n",
    "    return new_sentences\n",
    "\n",
    "\n",
    "symbol_pattern = r'^[.!?]+'\n",
    "leader_pattern = r'[.・]{2,}'\n",
    "end_of_sentence_pattern = r'[。!?]$'\n",
    "compiled_symbol = re.compile(symbol_pattern)\n",
    "compiled_leader = re.compile(leader_pattern)\n",
    "compiled_eos = re.compile(end_of_sentence_pattern)\n",
    "\n",
    "\n",
    "def join_symbol_only_sentence(sentences):\n",
    "    sentence_length = len(sentences)\n",
    "    new_sentences = []\n",
    "    is_matched = False\n",
    "    \n",
    "    for i in range(sentence_length):\n",
    "        if is_matched:\n",
    "            is_matched = False\n",
    "            continue\n",
    "        \n",
    "        if (compiled_symbol.match(sentences[i]) is None\n",
    "            or i == 0):\n",
    "            new_sentences.append(sentences[i])\n",
    "            continue\n",
    "        \n",
    "        new_sentences[-1] += sentences[i]\n",
    "        should_skip = True\n",
    "    \n",
    "    return new_sentences\n",
    "\n",
    "\n",
    "def restore_leader(sentences):\n",
    "    return [compiled_leader.sub('…', sentence)\n",
    "            if compiled_leader.search(sentence)\n",
    "            else sentence for sentence in sentences]\n",
    "\n",
    "\n",
    "def delete_sentence_only_symbols(sentences):\n",
    "    return [s for s in sentences if s != '、']\n",
    "\n",
    "\n",
    "def join_sentence_if_start_left_paren(sentences):\n",
    "    new_sentence = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if i == 0:\n",
    "            new_sentence.append(sentence)\n",
    "            continue\n",
    "        \n",
    "        if sentence[0] == '(':\n",
    "            new_sentence[-1] += sentence\n",
    "        else:\n",
    "            new_sentence.append(sentence)\n",
    "    \n",
    "    return new_sentence\n",
    "\n",
    "\n",
    "def fix_end_of_sentence(sentences):\n",
    "    return [sentence if compiled_eos.search(sentence)\n",
    "            else sentence + '。' for sentence in sentences]\n",
    "\n",
    "\n",
    "def make_sentences_from_feature(feature):\n",
    "    sentences = separate_sentence(\n",
    "        replace_number_to_zero(\n",
    "            delete_irregular_str(\n",
    "                fix_multiple_punctuation(\n",
    "                    fix_tilde(\n",
    "                        delete_slash(\n",
    "                            delete_emoji(\n",
    "                                delete_kaomoji(\n",
    "                                    replace_emoji(feature)\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return fix_end_of_sentence(\n",
    "        join_sentence_if_start_left_paren(\n",
    "            delete_sentence_only_symbols(\n",
    "                restore_leader(\n",
    "                    join_symbol_only_sentence(\n",
    "                        fix_bracket(\n",
    "                            fix_bracket(\n",
    "                                fix_bracket(\n",
    "                                    sentences, '「', '」'),\n",
    "                                '『', '』'),\n",
    "                            '(', ')')\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d06bdbc-2e09-409f-8342-c67d776736ee",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb0e3f8-dd67-4020-a04b-498d9adeeab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "for i, data in baseData.iterrows():\n",
    "    feature = data[\"text\"]\n",
    "    feature = unicodedata.normalize('NFKC', feature) # NFKC正規化\n",
    "    # emoji_list = extract_emoji(feature)\n",
    "    result = make_sentences_from_feature(feature)\n",
    "    line_length = len(result)\n",
    "    sentence = ' '.join(result)\n",
    "    features.append([i, line_length, sentence]) # [index, 文章数, 本文]\n",
    "    # for sentence_i, sentence in enumerate(result):\n",
    "    #     # index, 何文章目か, 文章数, 本文\n",
    "    #     features.append([i, sentence_i, len_result, sentence]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d6f7132-d011-429f-9cce-fda5d0b55f99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2, '最近の内容は、のび太が、他力本願ですぐ調子にのり、エゴが強すぎると感じている。 子供に見せたくないアニメになった。'],\n",
       " [1, 2, 'ヤクルトの舌や喉に何か残る感じの、あれは何でしょう? すごくいやだ。'],\n",
       " [2, 2, 'めばちこ痛い。 治ってもまたできる…。'],\n",
       " [3, 2, 'タケダは、からだ浸透補水液は病院の消毒液を連想させる味がします。 体に良くても飲み物としてなじまない味ですねっ。'],\n",
       " [4, 1, 'チョコリングの個性が弱くて商品として地味で美味しくない。'],\n",
       " [5, 2, 'ペットボトルは両手を使わないと開けられないので不満。 片手ワンタッチで開けられるものがあればいいなぁ。'],\n",
       " [6, 2, '水道の蛇口のランプがなぜ赤色なんでしょうか。 水色が青色のランプにして欲しかった。'],\n",
       " [7, 1, '動画を見てポイントを貯めるのがあるが、動画によっては何度見てもポイントが反映されないものがある。'],\n",
       " [8, 2, 'わかるとすでにあるって意味ある? 間違って押してもキャンセルできないしべつになくていい。'],\n",
       " [9, 1, 'ディスカウントショップで非常口前に安売り商品が山積みして有り、もしもの時に危ない。']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
